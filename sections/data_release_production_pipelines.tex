\section{Level 2 Pipelines}

\subsection{PSF Estimation Pipeline (\wbsPSF)}

\subsubsection{Key Requirements}

PSF Estimation pipeline must enable the estimation of the zero-intensity point spread function at any point on the focal plane with residual ellipticity correlations at the levels required by LSR-REQ-0097.

\subsubsection{Baseline Design}

LSST's PSF models will be implemented as a plugin. Simple PSF estimation algorithms (e.g., {\tt pcaPsf}) will be implemented by the Single Frame Processing pipeline (\wbsSFM). The CoaddPsf algorithm will be implemented in the Image Coaddition Pipeline (\wbsCoadd).

Current state-of-the-art PSF estimation methods typically use some basis functions (e.g., $\delta$-functions, PCA) and a spatial model (e.g., polynomials) to estimate the PSF\@. This is not expected to be sufficient to reach LSST requirements. We have therefore adopted the following baseline:
\begin{itemize}
    \item Decompose the PSF into a component due to the atmosphere and a component due to the telescope and camera system.
    \item Estimate the telescope+camera component using the wavefront sensor information (the reconstructed wavefront) and camera metrology (the laboratory or on-sky measurement of $z$ offsets of individual sensors)
    \item Estimate the atmospheric contribution by modelling the PSF from bright, isolated, stars, and interpolating using Kriging. % RHL PCA \'a la Jarvis and Jain only works for the camera part
\end{itemize}

This estimation will be performed on the full focal plane. It will make use of wavefront sensor information and camera metrology provided by the Telescope \& Site subsystem, and use the per-CCD estimates of the PSF and cutouts of bright stars (PSF estimation candidates) to determine the atmospheric contribution. The latter may be augmented by including a physical model of the atmosphere.

In thick deep depletion devices such as LSST, the electric field from photoelectrons distorts the pixel grid, giving bright objects a broader effective PSF than faint objects.  We expect most and perhaps all correction for this effect to happen in Instrument Signature Removal (part of \wbsSFM), but we may need to mitigate residuals from that correction in PSF estimation, likely by iteratively forward-modeling the estimated zero-intensity PSF until convergence is achieved. The same forward-modelling algorithm will allow us to estimate the PSF in undersampled imaging, as is expected for roughly the best quartile of the seeing distribution; the resulting estimate should not be of lower quality that of an equivalent well-sampled PSF assuming that enough stars are included in the model.

It is necessary to take account of chromatic effects from both the atmosphere and the telescope optics when creating the PSF model. It is well understood how the optical and atmospheric components of the PSF should depend on wavelength, so any model that separates these components effectively should automatically include the correct chromatic dependency, allowing it to be evaluated at any wavelength or (assuming color-indepedent morphology) the SED of a particular source.  This will allow us to validate and constrain the chromatic dependence of the model using the known or inferred SEDs of stars.

\subsubsection{Constituent Use Cases and Diagrams}

Perform Full Focal Plane PSF Estimation.

\subsubsection{Prototype Implementation}

Prototype code for wavefront reconstruction has been developed by the LSST Telescope and Site group. We expect this code will be rewritten in Construction to follow LSST Data Management standards and be straightforward to incorporate into the PSF Estimation pipeline.
\\

The remaining components of the PSF Estimation pipeline have not been prototyped at this time.

\clearpage

\subsection{Image Coaddition Pipeline (\wbsCoadd)}

\subsubsection{Key Requirements}

The Image Coaddition Pipeline will produce coadds given a stack of input calibrated exposures. Generated coadds must be characterized, at a pixel level, for validity and variance (i.e., have a Mask plane and a Variance plane). It must be capable of supporting these coaddition schemes within a single band:

\begin{itemize}
    \item{Direct;}
    \item{PSF-matched;}
    \item{Likelihood (``Kaiser'').}
\end{itemize}

The implementation of likelihood coaddition used to generate coadds suitable for the Detection and Deblending system (\wbsDetDeblend{}) may utilize extensive approximations that limit the applicability of the coadds in the Object Characterization Pipeline (\wbsObjChar{}). A prototype version of likelihood coaddition algorithm suitable for object characterization must also be developed within this WBS; whether that more advanced algorithm progresses beyond prototype stage will be determined within \wbsObjChar{}.

The baseline implementation of likelihood coaddition may utilize extensive approximations that limits the applicability of the coadds in the Object Characterization Pipeline (\wbsObjChar). A higher quality implementation need only be implemented in response to emergent object characterization requirements during construction.

The Image Coaddition Pipeline must be capable of combining coadds from multiple bands into a single, multi-band, coadd. When doing so, it must support both the ``$\chi^2$'' scheme described by \cite{Szalay99} and a scheme in which inputs are weighted by the expected SED.

When non-PSF-matched coadds are produced, the effective PSF and its variation across the full coadd must be determined and retained.

Outliers appearing in a small subset of input images (e.g.\ transients or moving objects) must not appear in the final co-adds. % RHL how we handle variables (e.g., RR Lyrae's) is not obvious

The Image Coaddition Pipeline must make it possible to generate the coadds from background-subtracted input images or perform partial background subtraction via matching during coaddition (\ref{alg:backgroundMatching}).

The pipeline must be capable of generating coadds in varying geometries and tessellations of the sky, plugged in at runtime via Python modules and configuration directives. To reduce its memory footprint, it should be capable of generating the coadds in small patches set by the operator at runtime via configuration directives.

The pipeline should be capable of co-adding undersampled images without aliasing.

For performance reasons, the pipeline should be able to simultaneously generate multiple coadds from the same input stack, avoiding unnecessary rewarping of inputs to generate each coadd.

\subsubsection{Baseline Design}

\paragraph{Coaddition}
\label{alg:coadd}

The Coaddition Pipeline will apply the results of the relative astrometric solution (developed as a part of Single Frame Pipeline, \wbsSFM) to the input images, warp (\S\ref{alg:warp}) them to a common coordinate system (``sky map''; \S\ref{alg:skymap}) and coadd the pixels. Multiple coadds may be created from a given set of input images by combining subsets of the input defined explicitly by the operator or algoritmically by quality cuts.

To accurately measure the colors of galaxies (e.g., for photometric redshifts) in the presence of intra-object color gradients, seeing changes and imperfect galaxy models, the baseline implementation will be capable of producing ``PSF-matched coadds'' using well known PSF-matching algorithms. The Object Characterization Pipeline (\wbsObjChar) will measure object properties on both direct (centroids and shapes) and PSF-matched (fluxes) coadds, as well as fitting galaxy models to the direct coaads.

Likelihood coaddition is required for detection in both the Image Difference Pipeline (\wbsDiffim{}) and the Detection and Deblending system (\wbsDetDeblend{}). It also presents a possible alternative to direct and PSF-matched coaddition for object characterization. Assessing the suitability of likelihood coadds for use in LSST data releases is contained within the Object Characterization Pipeline (\wbsObjChar); the Image Coaddition Pipeline will deliver likelihood coadds as required to satisfy that requirement.

The Detection and Deblending system (\wbsDetDeblend) will make use of multi-band coadds. These may be generated either using the $\chi^2$ algorithm \cite{Szalay99} or based on SED-weighted combinations of per-band coadds. The Image Coaddition Pipeline will make it possible to generate either of these on demand.

If the seeing is not constant it becomes impossible to produce a coadd with a PSF varying in a continuous fashion over the field, unless the data is deliberately degraded by convolving the inputs to a common PSF (known as ``PSF matching").  In order to enable dealing with the discontinuous PSF, the Coaddition Pipeline will construct a ``CoaddPsf'' (\S\ref{alg:coaddPsf}) PSF model, which is a sum of the PSFs of the input images at each point of interest (as proposed as part of `StackFit' \cite{Jee13}).

Determining the background from individual visits separately is problematic (because different choices can be made in each, especially at the edge of a CCD; and because extended, faint astrophysical flux is misinterpreted as background), commonly manifesting as dark rings around very bright stars and the suppression of extended flux around galaxies. Therefore, the pipeline will include the capability to perform ``background matching'' (\S\ref{alg:backgroundMatching}) to produce a coadd with a high signal-to-noise realization of the background in a single reference exposure.  This background will be measured over large scales and be possible to subtract with a high degree of accuracy. Background matching will be the default mode of operation. Nevertheless, it will also be possible to produce coadds by subtracting the background first using Sky Background determination and substraction components developed in the Single Frame Processing Pipeline (\wbsSFM).

\paragraph{Warping}
\label{alg:warp}

To warp an image from the detector frame to the sky frame, a resampling kernel will be used. The kernel is set according to the sub-pixel position on the input image of the centre of the corresponding output pixel. This must support Lanczos (of configurable order), bilinear or nearest-neighbour kernels, with the default being a 3rd-order Lanczos (with $10^6$ cache realizations), as a compromise between the infinite \emph{sinc} function and the need for speed. Other schemes (e.g.\ polynomial interpolation) may also be available.

The LSST focal plane will be undersampled at seeing less than 0.4''. It must be possible to warp and coadd undersampled images without introducing aliasing. The approach taken should provide the best possible image quality while maintaining adequate computational throughput; a slight loss of image quality is acceptable.

\paragraph{Background Matching}
\label{alg:backgroundMatching}

Background matching will be implemented to enable reaching the maximum depth in the coadds and preserve the astrophysical backgrounds.  We adopt as our baseline the algorithm of Huff et al. \cite{Huff11}, extended to two-dimensional data.

The common practice of subtracting the background from each input individually removes features on moderate scales (such as the outer haloes of galaxies, and Galactic cirrus) and can be unstable (especially when the features appear at the edge of a frame) causing increased noise.

Instead, the following algorithm (following Huff et al.) will be implemented: the pipeline will choose one or more reference exposures, and match the backgrounds of each of the other exposures to the reference.  This will be done by subtracting the reference from each of the other exposures (which mostly removes astrophysical sources, especially the extended sources which normally contaminate background measurement) and fitting a background model to the difference between the backgrounds\footnote{It is anticipated this code will be shared with the Sky Background determination modules from the Single Frame Processing pipeline.}. These models will then be subtracted from the other inputs, so that all exposures have the same large-scale background as the reference exposure. 

The coadd produced with the above algorithm will retain the extended astrophysical features at high signal-to-noise, and the background can be carefully removed over multiple patches at once. The subtracted image also provides an opportunity to identify sharp features such as optical ghosts, glints and other contaminants that can be masked.

\paragraph{Sky Tessellation and Coadd Projections}
\label{alg:skymap}

The ``skymap'' is a tessellation of the sky, providing suitable pre-defined coordinate systems for operations on the sky such as coaddition.  The sky map divides the sky into ``tracts''.  For convenience and parallelism, each tract is sub-divided into ``patches''.  Tracts and patches may overlap, so that sources are not lost in the gaps. Tessellations will be pluggable Python modules.
\\

The baseline tessellation is one using a stereographic dodecahedron. The sky will be subdivided into 12 overlapping\footnote{We're planning for 3.5 degrees of overlap, roughly accommodating a full LSST focal plane.} {\em tracts}, spanning approximately $75 \times 72$ degrees. The sky will be stereographically projected onto the tracts\footnote{See \url{https://dev.lsstcorp.org/trac/wiki/DM/SAT/SkyMap} for details.}, and pixelized into (logical) images 2.0 x 1.9 megapixels in size (3.8 terapixels in all). Physically, these large images will be subdivided into smaller, approximately $2{\rm k} \times 2{\rm k}$ pixel, non-overlapping, {\em patches}, though that subdivision is to be transparent to clients. Clients will be able to request arbitrarily chosen regions in each tract\footnote{Up to some reasonable upper limit, defined by available memory}, and receive them back as afw {\tt Exposure} objects.

\paragraph{CoaddPsf}
\label{alg:coaddPsf}

One of the main challenges in producing quality measurements from
non-PSF-matched coadds is the complexity of the effective point-spread
function on the coadd.  Because the PSF has discontinuities at the
location of chip boundaries, modeling approaches based on
interpolating with smooth functions cannot be used.  Instead, when
creating a coadd image, we also combine the PSF models of all the
input exposures, using an approach similar to that devised by
Jee and Tyson \cite{JeeTyson11}.  This combination is lazy, in that we simply store the
PSF models, their bounding boxes, and the coordinate transforms that
relate them to the coadd pixel grid.  Then, when measuring an object
on the coadd, we obtain the coadd PSF model at that location by coadding the
PSF models of all exposures that contributed to the relevant part of
the coadd, after warping them by the appropriate coordinate
transform.  We approximate the PSF as spatially constant in the region
of an individual object.

%This approach is not exact in the presence of missing data.  When a
%particular exposure pixel does not contribute to the coadd, the
%associated PSF should not contribute as well, but the cost of storing
%a mask mapping these rejected pixels along with the PSF is currently
%prohibitively expensive, so the PSF combination algorithm does not
%consider rejected or masked pixels.  More importantly, when only
%certain pixels that contribute to an object are rejected, the PSF
%model on the coadd is not well-defined for that object; we cannot
%represent the coadd as the convolution of an idealized astrophysical
%object with any convolution kernel.  This is a particular problem for
%stars that are near the saturation limit: if they are saturated in
%some frames, but not others, accurate coadd measurements become
%essentially impossible.  Cosmic rays will also contribute to this
%effect for many more objects, but at a lower level, and objects whose
%isophotes cross a chip boundary in one or more input exposures will
%also be affected.  It is worth noting that this requires coaddition to be 
%based on a straightforward mean with as little clipping as possible; both median
%stacking and aggressive clipping will cause the PSF of the coadd to be
%poorly-defined, and a poor match to the model produced by the CoaddPsf
%approach.

\paragraph{Image artifact rejection}

\begin{note}[TODO]
This is a placeholder by JDS --- a fuller description of the approach is required.
\end{note}

Artifacts which may be seen on images include:

\begin{itemize}
  \item{Optical ghosts and glints;}
  \item{Satellite and asteroid trails;}
  \item{Transient and variable sources.}
\end{itemize}

These must not be included in coadds. Furthermore, the \texttt{CoaddPsf} must be updated to take account of their removal.

\paragraph{Differential Chromatic Refraction}

The baseline design for difference imaging (\wbsDiffim) calls for creation of coadds in bins of different airmass to account for differential chromatic refraction. However, initial work suggests better results may be achieved by modelling and compensating for DCR when templates are being constructed \cite{Becker14}. A similar approach will also be investigated when building coadds for deep detection (\wbsDetDeblend). A prototype DCR compensation algorithm should be developed in this WBS based on an assumed SED; further development will be driven by future requirements from other WBS elements.

\subsubsection{Constituent Use Cases and Diagrams}

Create Deep Coadd Exposures; Create Short Period Coadd Exposures; Coadd Calibrated Exposures; Create Best Seeing Coadd Exposures; Create PSF-matched Coadd Exposures;
Create Template Exposures;

\subsubsection{Prototype Implementation}

A prototype implementation of all major components of the Coaddition Pipeline baseline design has been completed in LSST Final Design Phase. We expect it will be possible to transfer a significant fraction of the existing code into Construction, for continued improvement to meet LSST performance and accuracy requirements.
\\

The existing prototype has been extensively tested with image simulation inputs, as well as real data (SDSS Stripe 82). Using Stripe 82 data, it demonstrated the benefits of background matching and CoaddPsf approaches.
\\

The design and performance of the current prototype pipeline is described in the Summer 2012 Data Challnge (\url{http://ls.st/vho}) and Winter 2013 Data Challenge Report (\url{http://ls.st/ofk}). The prototype codes are available in the {\tt coadd\_*} git repositories browsable through the LSST git repository browser at \url{https://github.com/lsst}.

\clearpage

\subsection{Object Detection and Deblending (\wbsDetDeblend)}

\subsubsection{Key Requirements}

The Object Detection and Deblending system is responsible for the detection of
sources on coadds produced by the Coaddition Pipeline and for disentangling
collections of superimposed objects into their constitutent parts.

\begin{note}[TODO]
There are no requirements specified for the coverage maps. For now, I am adding a vague statement here. We should make this more concrete, perhaps by updating the DMSR.
\end{note}

It must also construct maps describing completeness and selection effects in
the LSST survey.

\subsubsection{Baseline Design}

The baseline is based on the SDSS detection and deblending algorithms \cite{LuptonPhoto, Lupton05}. See also the notes on Deep Processing available on Confluence\footnote{\url{https://confluence.lsstcorp.org/display/DM/Deep+Processing}}.

\paragraph{Object detection}
\label{alg:detection}

Object detection on a single image is performed by correlating the image with the
CoaddPsf PSF and searching for peaks above the preset threshold. Multiple
adjacent peaks will be detected and merged to reduce spuriously detected
objects due to noise or object substructure.

To enable detection of extended objects, the Pipeline will perform detection on
recursively binned coadds.

To construct the object catalog, detection may be performed on multiple different types of coadd, as generated by the Image Coaddition Pipeline (\wbsCoadd{}). These may include coadds from multiple separate bands, multi-band coadds, and coadds made with different algorithmic approaches (direct, likelhihood, etc). Detection is performed on each coadd independently, then a \textit{peak association} procedure combines the detection outputs from different coadds, merges footprints that cover the same patch of sky and associates peaks that (we believe) correspond to the same object. This association procedure may also incorporate other sources, e.g.\ transient and moving sources detected in image differencing (\wbsDiffim{}) and known objects from other surveys. The result is a set of merged, non-overlapping footprints, each containing one or more peaks.

Per \S\ref{alg:skymap}, the sky is tessellated into overlapping tracts and patches. In general, these may be processed independently, but care is required to ensure that objects which appear in the overlapping regions appropriately merged rather than being duplicated.

\begin{note}[TODO]
Define how this merge will take place.
\end{note}

The \DPDD{} requires that the resultant collection of peaks and their
membership in the footprints be provided to end users as a \texttt{CoaddSource}

\paragraph{Deblender}
\label{alg:deblender}

At the depths probed by LSST images, many of the sources are superimposed on each other on the sky (``blended''), which makes detecting and measuring such sources difficult.  Often this blending is not severe, but the footprints of reasonably well separated objects can overlap (and therefore merge together) slightly.  In other cases, distinct objects will be superimposed directly on more extended objects (e.g., a star on a resolved galaxy). % RHL I didn't like 5\sigma contours as a 5\sigma object is a single pixel, and it's the growing that makes it overlap.

In order to disentangle the multiple objects, we adopt a baseline for the ``deblender'' based on the algorithms used in SDSS.

The baseline deblender assumes that discrete sources generally have twofold
rotational symmetry.  When one side of a source is blended, we can
recover its appearance by examining the symmetric side.  The deblender
begins by building these symmetric templates for each source.  Next,
the flux in each pixel is split among the blended source in proportion
to their templates.  The deblender produces cutouts of each
source in a blended group, so that the measurement algorithms (fluxes,
galaxy shapes, etc) need not know that the source was blended. This deblending algorithm works well in practice for moderately crowded fields (as demonstrated by SDSS).

This SDSS-style deblender will be run on one or more single-band coadds. When deblending across multiple bands, the deblender must ensure that consistent results are achieved across all bands.

After deblending, a set of PSF-convolved models will be fit to the deblended children. The initial templates with then be replaced by these models, convolved with the appropriate PSF, and flux assigned as before. The use of physically-motivated templates will help with identification and reduction of non-physical deblends, generalization to multi-epoch data, and data with very different image quality.  Fitting these model templates will also allow us to improve centroids of objects whose positions were affected by their neighbors. % RHL I even spelt it in American

In areas of significant stellar crowding (i.e., Galactic plane, star clusters), this approach lends itself to imposition of appropriate template priors (i.e., the correct template being that of a point source convolved with the PSF). This, effectively, makes the deblender into a crowded field code, allowing this baseline to satisfy the requirements for crowded field photometry.

\begin{note}
The ``divide and conquer'' technique needs to be properly fleshed out.
\end{note}

The deblender must be capable of handling extremely large blended sources using a so-called ``divide-and-conquer'' approach to split them up and handle them in manageable pieces.

\paragraph{Sky coverage}

This is an area of active and ongoing research in DES and HSC\@. We intend to learn from their experience before baselining a design. Relevant prior work includes STOMP\footnote{\url{https://code.google.com/p/astro-stomp/}}, Mangle\footnote{\url{http://space.mit.edu/~molly/mangle/}} and Venice.

\subsubsection{Constituent Use Cases and Diagrams}

\begin{note}
The UML models are comprehensively outdated.
\end{note}

Detect and Characterize AstroObjects;
Detect Sources on Coadds;

\subsubsection{Prototype Implementation}

A functional detection and deblending system was completed in the LSST Final Design Phase and has and extensively tested with image simulation inputs as well as real data (SDSS Stripe 82). A significant fraction of this code has been transferred into Consturction.

The multi-band processing architecture has been prototyped on HSC and is now available in the LSST codebase.

The detection functionallity is a part of the {\tt afw} package browsable through the LSST git repository browser at \url{https://github.com/lsst/afw }; deblending functionality is in the {\tt meas\_deblender} package at \url{https://github.com/lsst/meas_deblender}; the multi-band processing architecture in \texttt{pipe\_tasks} at \url{https://github.com/lsst/pipe_tasks}.

\clearpage

\subsection{Object Characterization Pipeline (\wbsObjChar)}

\subsubsection{Key Requirements}

\begin{note}
Here we account to itemize all the pieces of functionality that the Obj Char Pipeline needs to meet the DPDD (or some Bosch Blended Measurement \cite{Bosch15} modified version thereof). Some of these are arguably design decisions rather than requirements on the output, but the contents of the DPDD are explicitly driven by the algorithmic and design decisions -- we commit to providing the results of certain measurements, which makes the measurements requirements.
\end{note}

Given one or more cutouts of a detected object, observed in one or more epochs, the Object Characterization Pipeline must perform all measurements required to generate the Level 2 Catalogs as described by the \DPDD{}, within the computational budget allotted by the LSST sizing model.

Functionally, the components of this pipeline must be available for incorporation into or use by other pipelines. In particular, both the Single Frame Processing Pipeline (\wbsSFM) and the Imaging Differencing Pipeline (\wbsDiffim) will delegate source characterization to the algorithms defined herein.

The Object Characterization Pipeline must be capable of:\footnote{The \DPDD{} specifies detailed algorithmic requirements for each of these measurements}
\begin{itemize}
  \item{Measurement of surface brightness in an elliptical aperture;}
  \item{Measurement of flux using a linear least squares fit with the model PSF (``PSF flux'');}
  \item{Computing flux as the dot product of an elliptical Gaussian weight function with the image (``Gaussian flux'');}
  \item{Measurement of Petrosian flux and radius;}
  \item{Measurement of Kron flux and radius.}
\end{itemize}

The Object Characterization Pipeline must be capable of fitting the following source models:
\begin{itemize}
  \item{Moving point source (required by Single Frame Processing);}
  \item{Trailed point source (required by the Image Differencing Pipeline);}
  \item{Hybrid galaxy-moving point source (required for Level 2 Catalogs).
    \begin{note}
    The \DPDD{} specifies separate point source and galaxy models; here we follow Bosch.
    \end{note}
  }
\end{itemize}

It must be possible to fit a point source model to an image while holding the postion, motion, shape and deblending parameters (if applicable) fixed (to perform ``forced photometry'').

It must be possible to perform \textit{simultaneous fitting}, whereby we fit the models for multiple objects simultaneously.

It must be possible to fit objects using either numerical optimization or by Monte Carlo sampling.

It must be possible to characterize sources in multiple epochs by fitting a parameterized model to each epoch (rather than co-adding the data and fitting to the result). This approach, which we term ``MultiFit'', is explored further in \S\ref{sec:multifit}.

When measuring the same object in coadds covering multiple bands, it must be possible to ensure the results are consistent (contain the same set of objects) in all filters. This is achieved by basing the measurement routines on the output of the peak association procedure defined in \S\ref{alg:detection} (Object Detection and Deblending; \wbsDetDeblend{}).

It must be possible to derive the following quantities based on the measurements made using ``best practice'' algorithms at the time of commissioning:
\begin{itemize}
  \item{Color of the object measured in the ``standard seeing'';}
  \item{Extendedness of the object;}
  \item{Photmetric redshift likelihood samples;}
\end{itemize}

It must be possible to characterize a time series of forced photometry measurements of the same object for aperiodic and periodic variability\footnote{The \DPDD{} suggests specific metrics, but cautions they should be revised during construction.}.

When constructing Level 2 Catalogs, a probabalistic star-galaxy classification should be available for each object.

\begin{note}
The \DPDD{} only specifically calls out DCR in the context of MultiFit for a point source model. That is presumably incomplete; our requirements for DCR in object characterization require fleshing out.
\end{note}

Per \S\ref{sec:diffimDesign}, the baseline design requires that measurement of point sources on likelihood coadds (also known as Kaiser coadds or detection maps) must be possible. It is possible that much of the other object characterization techniques described in this baseline may be reconsidered and replaced with measurements made on likelihood coadds \cite[\S8.2.1]{Bosch15}; see also the discussion of the Image Coaddition Pipeline, \wbsCoadd{}. To facilitate the best possible science outputs, this baseline allocates time to explore the scientific potential of likelihood coaddition in terms of both theoretical work the mathematical formalism and the development of proof-of-concept measurements, with the possibility of rebaslining during construction if necessary.

\begin{note}
Can we define specific success criteria for experimenting with likelihood coaddition?
\end{note}

\subsubsection{Baseline Design}

\paragraph{Single-epoch Characterization}

Single-epoch (including coadd) object characterization will primarily rely on forward-modeling. Models will be convolved with the independently estimated PSF and compared with the pixel data until $\chi^2$ is minimized. % RHL I'm not sure that we'll exactly minimise chi^2.  For example, including the object's contribution to the variance gives magnitude-dependent biases.

%Multi-epoch object characterization will follow the single-epoch prescription, with the data and model vectors being extended to simultaneously fit observations at multiple epochs. We term this fitting method {\em MultiFit}. At its core, MultiFit a relatively
%straightforward observation that it is better to fit a PSF-convolved
%model to individual epochs, than generate a (potentially PSF-matched)
%coadd and fit the model to the resultant image. Assuming Gaussian
%errors, MF is exactly equivalent to least squares. If the PSF is known (which is a
%separate problem solved by the PSF Estimation pipeline, \wbsPSF), implementation is straightforward and easy to write. This is, however, computationally challenging as each iteration of the model fitter requires a convolution of potentially hundreds of models (one for each epoch), on a grid that oversamples the pixel grid by a factor of few.

\paragraph{MultiFit}
\label{sec:multifit}

For multi-epoch characterization and some science measurements --- particularly shape measurement for weak
lensing --- measurement on a coadd image may not provide the necessary
precision and control of systematics.  To perform these measurements,
we baseline the ``MultiFit'' approach \cite{Bosch10, Bosch13}, in which a
parametrized model for each astronomical object is fit simultaneously
to all of the data in which that object appears.  Rather than
transform and combine the data, we instead transform the model to the
coordinate system of each exposure, convolve it by the appropriate
PSF, and compare it to the data from that exposure.  Measurements from
the coadd will be used as a starting point, so the MultiFit processing
will proceed by iterating over the catalog generated from the coadd,
loading postage stamps from the original images, and fitting to these
data.  Note that the output measurements will generally have the same
form as the coadd-based measurements - one set of measurements per
astronomical object. There is a single set of the
parameters that describe each object, not a different set of parameters
for each exposure in which it appears.

Because it does not involve transforming noisy data (which is usually
lossy in some sense), and instead transforms analytic models, a
MultiFit approach is theoretically optimal for measurements that can
be framed as the results of model-based fits to the data (note that
not all measurements can be framed in such a way, but those that
cannot usually do not properly account for the PSF). % RHL I think that this is correct, but things like Petro quantities that are measured from apertures can probably be estimated from psf-corrected apertures, measured in a multifit way.  I'm not sure if I think this is a good idea
While it may be
possible to construct an optimal coadd that would also be
theoretically optimal, we expect that the difficulty in creating such
a coadd (i.e., perfectly tracking the covariances between pixels
introduced by resampling to a common pixel grid) would be prohibitively
complex.  On the other hand, for many measurements a non-optimal coadd
may be practically
sufficient, in the sense that the improvement produced by a
MultiFit-based measurement of the same would be negligible.  In these
cases, the coadd measurement is likely to be far more efficient
computationally.  Whenever possible, then, we will do as much work as
possible on the coadd first, and only use a MultiFit approach to ``tune up''
the final result.  And when this final tuning is determined to be
unnecessary, it can be skipped entirely.

To further make the MultiFit approach computationally tractable, we baseline use the multi-shapelet MultiFit algorithm implementation, as described in \cite{Bosch13}.

\paragraph{Point source model fit}

To satisfy the point-source model fit requirements, we model each observed object as a point source with finite proper motion and parallax and with constant flux (allowed to be different in each band). This model is a good description for stars and other unresolved sources. Its 11 parameters will be simultaneously constrained using information from all available observations in all bands. Per \S5.2.1 of the DPDD, the fitting procedure will account for differential chromatic refraction. The fitting procedure will account for differential chromatic refraction. MultiFit will be used to perform the fit.

\paragraph{Bulge-disk model fit}
\label{alg:bulgedisk}

\begin{note}
Deprecated by Bosch.
\end{note}

To satisfy the bulge-disk model fit requirements, the pipeline will be capable of modelling objects as a sum of a de Vaucouleurs (S\'ersic $n=4$) and an exponential (S\'ersic $n=1$) component. This model is a reasonable description of galaxies. The object is assumed not to move (i.e., have zero proper motion). The components share the same ellipticity and center. The model is independently fit to each band. There are a total of 8 free parameters, which will be simultaneously constrained using information from all available epochs for each band. Where there's insufficient data to constrain the likelihood (eg., small, poorly resolved, galaxies, or very few epochs), the pipeline will have the capability to take into account priors that limit the range of its sampling.

In addition to the maximum likelihood values of fitted parameters and their covariance matrix, the pipeline shall be capable of sampling independent samples from the likelihood function (or posterior). MultiFit will be used to perform the fit.

\paragraph{Trailed model fit}

The pipeline shall be capable of fitting a trailed object model, as described in the \DPDD{}. The baseline algorithm is analogous to that employed by the bulge-disk model fit, but with the model being a line segment instead of a mixture of S\'ersic profiles.

\paragraph{Dipole model fit}

Dipole model fitting is provided directly within the Image Differencing Pipeline (\wbsDiffim{}; \S\ref{alg:dipole}); this section is maintained to avoid renumbering breaking references to this document.

\paragraph{Hybrid model fit}

\begin{note}
Required by Bosch. Need specifications as to the form the model will take, particularly as relates to requirements for galaxy modelling in DLP; we baseline it as being ``advanced'' relative to CModel, but specify nothing else at present.
\end{note}

The pipeline shall be capable of fitting a hybrid model that transitions between a moving point source and a galaxy model. Because a static point source is a limit shared by both models, the transition is continuous. Fitting will be performed by both numerical optimization and Monte Carlo sampling; where there iss insufficient data to constrain the likelihood (eg., small, poorly resolved, galaxies, or very few epochs), the pipeline will have the capability to take into account priors that limit the range of sampling. The model is independently fit to each band.

\paragraph{Centroids} Centroids will be computed independently for each band using an algorithm similar to that employed by SDSS \cite{LuptonPhoto}. Information from all epochs will be used to derive the estimate. These centroids will be used for adaptive moment, Petrosian, Kron, standard color, and aperture measurements.

\paragraph{Adaptive moments} Adaptive moments will be computed using information from all epochs, independently for each band, using the algorithm of Bernstein \& Jarvis (2002).

\paragraph{Petrosian and Kron fluxes} Petrosian and Kron radii and fluxes will be measured in standard seeing using self-similar elliptical apertures computed from adaptive moments. The apertures will be PSF-corrected and \emph{homogenized}, convolved to a canonical circular PSF\@. This is in order to derive a definition of elliptical apertures that does not depend on seeing. For example, for a large galaxy, the correction to standard seeing will introduce little change to measured ellipticity. Corrected apertures for small galaxies will tend to be circular (due to smearing by the PSF). In the intermediate regime, this method results in derived apertures that are relatively seeing-independent. Note that this is only the case for \emph{apertures}; the measured flux will still be seeing dependent and it is up to the user to take this into account.

The radii will be computed independently for each band. Fluxes will be computed in each band, by integrating the light within some multiple of \emph{the radius measured in the canonical band}. The shape of the aperture in all bands will be set by the profile of the galaxy in the canonical band alone. This procedure ensures that the color measured by comparing the flux in different bands is measured through a consistent aperture. See \url{http://www.sdss.org/dr7/algorithms/photometry.html} for details. The pipeline shall be capable of computing radii enclosing 50\% and 90\% of light.

The baseline for both Petrosian and Kron flux implementation is to derive these as an a mathematical transformation of aperture surface brightness measurements (see below).

\paragraph{Aperture surface brightness} Aperture surface brightness will be computed in a variable number, depending on the size of the source, of concentric, logarithmically spaced, PSF-homogenized, elliptical apertures, convolved to standard seeing.

\paragraph{Resolved/Unresolved object separation}
\label{alg:star-galaxy}

We baseline the resolved/unresolved object separation algorithm based on the ratio of PSF and model fluxes. We use the extendedness criterion as defined by the HSC \cite{Furusawa14}:
\begin{equation}
{\rm extendedness} = (0.95\times {\rm flux.gaussian} < {\rm flux.psf})\, ?\, 0.0 : 1.0 \nonumber
\end{equation}

\paragraph{Star-Galaxy classification}

\begin{note}
Not explicitly required in any of the requirements documents, but common consensus is that this will be necessary. Should expand the below.
\end{note}

We expect to adopt the technique used by HSC\@: a sigmoid based on the difference between the model and Gaussian flux, trained using Support Vector Machines.

\paragraph{Colors}

The \DPDD{} requires that the pipeline provide the color for each object using some (unspecified) algorithm which is guaranteed to be independent of seeing and suitable for determination of photometric redshift (\S\ref{alg:photoz}).

Our default assumption is that all model fitting on coadds is performed to direct coadds, which will produce the best estimates of structural parameters and a more apppropriate starting point for Monte Carlo sampling. However, measuring galaxy colours to the required level of fidelity may require fitting to PSF-matched coadds \cite[\S8.2.2]{Bosch15}. We therefore plan to prototype color measurement on both direct and PSF-matched coadds, preferring the former for reasons of efficiency but being ready to take the latter to operations if required.

\paragraph{Photometric Redshifts}
\label{alg:photoz}

\begin{note}[TODO]
Define properly.
\end{note}

DMS-REQ-0046 requires that a photometric redshift be calculated for all Objects. The \DPDD{} requires that we provide 100 pairs of ($z$, $\log L$) likelihood samples for each object using an algorithm which is ``widely accepted at the time of LSST commissioning''.

\paragraph{Variability Characterization}

Two groups of parameters are required to be provided (see {\tt lcPeriodic} and {\tt lcNonPeriodic} in the \DPDD), designed to characterize periodic and aperiodic variability features. We baseline the metrics and algorithms described in \cite{Richards11} for production of these data products.

\subsubsection{Constituent Use Cases and Diagrams}

Measure AstroObjects; Exposure Stack Measurements;
Create Sky Coverage Maps; Perform Deblending and Association; Perform Forced Photometry; Characterize AstroObject Flux Variability;

\subsubsection{Prototype Implementation}

A prototype implementation of all major components of the Object Characterization Pipeline baseline design has been completed in LSST Final Design Phase. The existing prototype has been extensively tested with image simulation inputs, as well as real data (SDSS Stripe 82). We expect it will be possible to transfer a significant fraction of the existing code into Construction, for continued improvement to meet LSST performance and accuracy requirements.
\\

Missing from the current prototypes are the moving point source fit (implemented algorithms assume the source does not move), the trailed source fit, and the aperture, Kron and Petrosian magnitudes using elliptical apertures (implemented algorithms assume the apertures are circular).
\\

The design and performance of the current prototype pipeline is described in the Summer 2012 Data Challenge (\url{http://ls.st/vho}), Winter 2013 Data Challenge Report (\url{http://ls.st/ofk}), and Summer 2013 Data Challenge Report (\url{http://ls.st/grd}). The codes are available in the {\tt meas\_*} git repositories browsable through the LSST git repository browser at \url{https://github.com/lsst}.
